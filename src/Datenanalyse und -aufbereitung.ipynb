{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datenanalyse und -aufbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas, Numpy importieren\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "\n",
    "#SciKit importieren\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PISA Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/PISA_Raw/Pisa_Math_Raw.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2c2a957d5fe1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#import csv file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_pisa_math\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/PISA_Raw/Pisa_Math_Raw.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#remove useless\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# data_pisa_math = data_pisa_math[data_pisa_math[\"SUBJECT\"] == \"TOT\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata_pisa_math\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_pisa_math\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"LOCATION\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"SUBJECT\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TIME\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/PISA_Raw/Pisa_Math_Raw.csv'"
     ]
    }
   ],
   "source": [
    "#import csv file\n",
    "data_pisa_math = pd.read_csv(\"../data/PISA_Raw/Pisa_Math_Raw.csv\")\n",
    "#remove useless  \n",
    "# data_pisa_math = data_pisa_math[data_pisa_math[\"SUBJECT\"] == \"TOT\"]\n",
    "data_pisa_math = data_pisa_math[[\"LOCATION\", \"SUBJECT\", \"TIME\", \"Value\"]]\n",
    "data_pisa_math.info()\n",
    "data_pisa_math.head(6)\n",
    "# m = data_pisa_math[data_pisa_math[\"TIME\"] == 2018]\n",
    "# m = m[m[\"SUBJECT\"] == \"TOT\"]\n",
    "# m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pisa Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv file\n",
    "data_pisa_read = pd.read_csv(\"../data/PISA_Raw/Pisa_Read_Raw.csv\")\n",
    "#remove useless  \n",
    "# data_pisa_read = data_pisa_read[data_pisa_read[\"SUBJECT\"] == \"TOT\"]\n",
    "data_pisa_read = data_pisa_read[[\"LOCATION\", \"SUBJECT\", \"TIME\", \"Value\"]]\n",
    "data_pisa_read.info()\n",
    "data_pisa_read.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PISA Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv file\n",
    "data_pisa_science = pd.read_csv(\"../data/PISA_Raw/Pisa_Science_Raw.csv\")\n",
    "#remove useless  \n",
    "# data_pisa_science = data_pisa_science[data_pisa_science[\"SUBJECT\"] == \"TOT\"]\n",
    "data_pisa_science = data_pisa_science[[\"LOCATION\", \"SUBJECT\", \"TIME\", \"Value\"]]\n",
    "data_pisa_science.info()\n",
    "data_pisa_science.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini-Koeffizient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import csv file\n",
    "data_gini = pd.read_csv(\"../data/income_inequality.csv\")\n",
    "#remove useless  \n",
    "# data_gini.head()\n",
    "data_gini = data_gini[data_gini[\"SUBJECT\"] == \"GINI\"]\n",
    "data_gini = data_gini[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "data_gini.columns = [\"LOCATION\", \"TIME\", \"GINI\"]\n",
    "\n",
    "# In Zeitreihen verwandeln\n",
    "data_gini_int = data_gini.pivot_table(\"GINI\", \"LOCATION\", \"TIME\")\n",
    "\n",
    "# transform back to normal df\n",
    "data_gini_int.columns.name = None               #remove categories\n",
    "data_gini_int = data_gini_int.reset_index()                #index to columns\n",
    "\n",
    "data_gini_labels = data_gini_int\n",
    "# print(data_gini_labels)\n",
    "\n",
    "# linear interpolieren\n",
    "data_gini_int = data_gini_int.drop([\"LOCATION\"], axis=1) \n",
    "\n",
    "data_gini_int = data_gini_int.interpolate(method=\"linear\", axis=1, limit_direction=\"both\")\n",
    "data_gini_int = pd.concat([data_gini_labels[\"LOCATION\"], data_gini_int]\n",
    "                            , ignore_index = False, axis=1)\n",
    "\n",
    "# print(data_gini)\n",
    "# print(data_gini_int)\n",
    "# turn every year column into own column entry\n",
    "data_gini_int = data_gini_int.melt(id_vars='LOCATION', \n",
    "                                     var_name=\"TIME\", value_name=\"GINI\")\n",
    "data_gini = data_gini_int\n",
    "data_gini.info()\n",
    "data_gini.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schüler-Lehrer-Betreuungsverhältnis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://databank.worldbank.org/reports.aspx?source=2&series=SE.SEC.ENRL.TC.ZS&country=#\n",
    "- https://data.oecd.org/teachers/students-per-teaching-staff.htm\n",
    "#### Ganzer Datensatz\n",
    "<p> \n",
    "    Jahre: 2005 - 2018 <br>\n",
    "    Subjects: EARLYCHILDEDU, PRY, SRY, TRY\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import csv file\n",
    "#str = students per teacher ratio\n",
    "data_str = pd.read_csv(\"../data/students_per_teacher.csv\")\n",
    "#remove useless  \n",
    "data_str = data_str[[\"LOCATION\", \"SUBJECT\", \"TIME\", \"Value\"]]\n",
    "\n",
    "# Jeder Bildungsbereich in eigene Spalte\n",
    "data_str = data_str.pivot_table(\"Value\", [\"LOCATION\", \"TIME\"], \"SUBJECT\")\n",
    "\n",
    "# transform back to normal df\n",
    "# data_str.columns = data_str.columns.droplevel(0) #remove amount\n",
    "data_str.columns.name = None               #remove categories\n",
    "data_str = data_str.reset_index()                #index to columns\n",
    "\n",
    "# rename\n",
    "data_str.columns = [\"LOCATION\", \"TIME\", \"STR_ECE\", \"STR_PRY\", \"STR_SRY\", \"STR_TRY\"]\n",
    "\n",
    "data_str = data_str.drop([\"STR_ECE\", \"STR_PRY\", \"STR_TRY\"], axis = 1)\n",
    "\n",
    "\n",
    "data_str.info()\n",
    "data_str.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import csv file\n",
    "data_str = pd.read_csv(\"../data/str_worldbank.csv\")\n",
    "\n",
    "data_str = data_str.replace({\"..\": np.nan})\n",
    "data_str.iloc[:, 4:26] = data_str.iloc[:, 4:26].apply(pd.to_numeric)\n",
    "\n",
    "emp = np.empty(10)\n",
    "emp[:] = np.nan\n",
    "\n",
    "year_dict = dict((year, emp) for year in range(1990, 2000))\n",
    "# print(year_dict)\n",
    "\n",
    "data_str_int = pd.DataFrame.from_dict(year_dict)\n",
    "data_str_int = pd.concat([data_str_int, data_str.iloc[:, 5:26]]\n",
    "                            , ignore_index = None, axis=1)\n",
    "data_str_int[1990] = data_str[\"1990 [YR1990]\"]\n",
    "\n",
    "# data_str = data_str[[\"Country Code\"]]\n",
    "data_str = data_str.rename(columns={\"Country Code\": \"LOCATION\"})\n",
    "\n",
    "# Interpolation\n",
    "# print(data_str_int.loc[0, :])\n",
    "data_str_int = data_str_int.interpolate(method=\"linear\", axis=1, limit_direction=\"both\")\n",
    "\n",
    "data_str = pd.concat([data_str[[\"LOCATION\"]], data_str_int]\n",
    "                            , ignore_index = None, axis=1)\n",
    "# print(data_str)\n",
    "# turn every year column into own column entry\n",
    "data_str = data_str.melt(id_vars='LOCATION', \n",
    "                                     var_name=\"TIME\",value_name=\"STR_SRY\")\n",
    "\n",
    "# jahre in einheitlichen float wert umwandeln\n",
    "mask = data_str[\"TIME\"].str.len() >= 5\n",
    "# print(data_str[mask][\"TIME\"].str[0:5])\n",
    "# alle time einträge die länger als 4 zeichen sind abschneiden\n",
    "data_str.loc[mask, [\"TIME\"]] = data_str[mask][\"TIME\"].str[0:5]\n",
    "# typecast; otherwise no merging possible\n",
    "data_str.TIME = data_str.TIME.apply(pd.to_numeric)\n",
    "\n",
    "# print(data_str[data_str[\"LOCATION\"] == \"DEU\"])\n",
    "data_str = data_str[data_str[\"TIME\"] >= 1999]\n",
    "data_str.info()\n",
    "data_str.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Migration\n",
    "- anscheinend nur alle 5 Jahre Daten verfügbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import csv file\n",
    "data_migration = pd.read_csv(\"../data/percentage of migrants.csv\")\n",
    "# data_migration.info()\n",
    "# Select all available data after 2000\n",
    "data_migration = data_migration[[\"Country Code\", \"2000\", \"2005\", \"2010\", \"2015\"]]\n",
    "data_migration = data_migration.rename(columns={\"Country Code\": \"LOCATION\"})\n",
    "\n",
    "# Interpolation\n",
    "data_migration_int = pd.DataFrame(dtype='float64')\n",
    "data_migration_int[\"2000\"] = data_migration[\"2000\"] \n",
    "data_migration_int[\"2001\"] = np.nan \n",
    "data_migration_int[\"2002\"] = np.nan \n",
    "data_migration_int[\"2003\"] = np.nan \n",
    "data_migration_int[\"2004\"] = np.nan \n",
    "data_migration_int[\"2005\"] = data_migration[\"2005\"] \n",
    "data_migration_int[\"2006\"] = np.nan \n",
    "data_migration_int[\"2007\"] = np.nan \n",
    "data_migration_int[\"2008\"] = np.nan \n",
    "data_migration_int[\"2009\"] = np.nan \n",
    "data_migration_int[\"2010\"] = data_migration[\"2010\"] \n",
    "data_migration_int[\"2011\"] = np.nan \n",
    "data_migration_int[\"2012\"] = np.nan \n",
    "data_migration_int[\"2013\"] = np.nan \n",
    "data_migration_int[\"2014\"] = np.nan \n",
    "data_migration_int[\"2015\"] = data_migration[\"2015\"]\n",
    "data_migration_int[\"2016\"] = np.nan \n",
    "data_migration_int[\"2017\"] = np.nan \n",
    "data_migration_int[\"2018\"] = np.nan \n",
    "\n",
    "data_migration_int = data_migration_int.interpolate(method=\"linear\", axis=1)\n",
    "\n",
    "data_migration = pd.concat([data_migration[[\"LOCATION\"]], data_migration_int]\n",
    "                            , ignore_index = None, axis=1)\n",
    "\n",
    "# turn every year column into own column entry\n",
    "data_migration = data_migration.melt(id_vars='LOCATION', \n",
    "                                     value_vars=[\"2000\", \"2003\", \"2006\", \"2009\", \"2012\", \"2015\", \"2018\"],\n",
    "                                     var_name=\"TIME\",value_name=\"MIGRANTS\")\n",
    "# typecast; otherwise no merging possible\n",
    "data_migration.TIME = data_migration.TIME.apply(pd.to_numeric)\n",
    "\n",
    "#log the migrant percentage\n",
    "# data_migration[\"log(MIGRANTS)\"] = np.log(data_migration[\"MIGRANTS\"])\n",
    "# data_migration = data_migration.drop([\"MIGRANTS\"], axis = 1)\n",
    "\n",
    "data_migration.info()\n",
    "data_migration.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP per Capita\n",
    "https://data.oecd.org/gdp/gross-domestic-product-gdp.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#GDP Daten werden eingelesen \n",
    "data_gdp = pd.read_csv('../data/gdp_pc.csv')\n",
    "\n",
    "#Daten zuschneiden\n",
    "data_gdp = data_gdp[['LOCATION', \"TIME\", 'Value']]\n",
    "#Value nach gdp umbenennen\n",
    "data_gdp = data_gdp[data_gdp[\"TIME\"] >= 1999]\n",
    "data_gdp = data_gdp.rename(columns = {'Value': 'GDP'})\n",
    "\n",
    "\n",
    "\n",
    "# In Zeitreihen verwandeln\n",
    "data_gdp_int = data_gdp.pivot_table(\"GDP\", \"LOCATION\", \"TIME\")\n",
    "\n",
    "# transform back to normal df\n",
    "data_gdp_int.columns.name = None               #remove categories\n",
    "data_gdp_int = data_gdp_int.reset_index()                #index to columns\n",
    "\n",
    "data_gdp_labels = data_gdp_int\n",
    "# print(data_gdp_int)\n",
    "\n",
    "\n",
    "# linear interpolieren\n",
    "data_gdp_int = data_gdp_int.drop([\"LOCATION\"], axis = 1)\n",
    "data_gdp_int = data_gdp_int.interpolate(method=\"linear\", axis=1, limit_direction=\"both\")\n",
    "\n",
    "# print(data_gdp_int)\n",
    "# Location spalte wieder hinzufügen\n",
    "data_gdp_int = pd.concat([data_gdp_labels[\"LOCATION\"], data_gdp_int]\n",
    "                            , ignore_index = False, axis=1)\n",
    "# print(data_gdp_int)\n",
    "\n",
    "# turn every year column into own column entry\n",
    "data_gdp_int = data_gdp_int.melt(id_vars='LOCATION', \n",
    "                                     var_name=\"TIME\", value_name=\"GDP\")\n",
    "\n",
    "data_gdp = data_gdp_int\n",
    "\n",
    "data_gdp.info()\n",
    "data_gdp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bildungsausgaben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_edu_spending = pd.read_csv(\"../data/education_spending/EducationSpendingTertiär2000_2016.csv\")\n",
    "data_edu_spending.head()\n",
    "\n",
    "data_edu_spending = data_edu_spending[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "data_edu_spending = data_edu_spending.rename(columns = {'Value': 'EDU_SPENDING'})\n",
    "\n",
    "# In Zeitreihen verwandeln\n",
    "data_pivot = data_edu_spending.pivot_table(\"EDU_SPENDING\", \"LOCATION\", \"TIME\")\n",
    "\n",
    "# transform back to normal df\n",
    "data_pivot.columns.name = None               #remove categories\n",
    "data_pivot = data_pivot.reset_index()                #index to columns\n",
    "\n",
    "# # leeren df mit Spalten für alle Jahre von 2000-2018 erstellen\n",
    "# emp = np.empty(data_pivot.shape[0])\n",
    "# emp[:] = np.nan\n",
    "# year_dict = dict((year, emp) for year in range(2000, 2019))\n",
    "# # print(year_dict)\n",
    "\n",
    "data_edu_spending_int = pd.DataFrame()\n",
    "\n",
    "\n",
    "# print(data_edu_spending_int)\n",
    "# data_pivot.info()\n",
    "# print(data_pivot)\n",
    "# print(data_pivot[2000])\n",
    "# print(data_edu_spending_int[\"2000\"])\n",
    "\n",
    "data_edu_spending_int[\"2000\"] = data_pivot[2000] \n",
    "data_edu_spending_int[\"2001\"] = np.nan \n",
    "data_edu_spending_int[\"2002\"] = np.nan \n",
    "data_edu_spending_int[\"2003\"] = np.nan \n",
    "data_edu_spending_int[\"2004\"] = np.nan\n",
    "data_edu_spending_int[\"2005\"] = data_pivot[2005] \n",
    "data_edu_spending_int[\"2006\"] = np.nan\n",
    "data_edu_spending_int[\"2007\"] = np.nan  \n",
    "data_edu_spending_int[\"2008\"] = data_pivot[2008] \n",
    "data_edu_spending_int[\"2009\"] = data_pivot[2009] \n",
    "data_edu_spending_int[\"2010\"] = data_pivot[2010] \n",
    "data_edu_spending_int[\"2011\"] = data_pivot[2011]\n",
    "data_edu_spending_int[\"2012\"] = data_pivot[2012] \n",
    "data_edu_spending_int[\"2013\"] = data_pivot[2013] \n",
    "data_edu_spending_int[\"2014\"] = data_pivot[2014] \n",
    "data_edu_spending_int[\"2015\"] = data_pivot[2015]\n",
    "data_edu_spending_int[\"2016\"] = data_pivot[2016] \n",
    "data_edu_spending_int[\"2017\"] = np.nan \n",
    "data_edu_spending_int[\"2018\"] = np.nan \n",
    "\n",
    "# data_edu_spending_int.info()\n",
    "# Estland 2000 manuell auf Nan setzten, da Wert=0 unrealistisch\n",
    "data_edu_spending_int.iloc[13, 0] = np.nan\n",
    "# print(data_edu_spending_int.iloc[13, :])\n",
    "\n",
    "data_edu_spending_labels = data_pivot\n",
    "# print(data_edu_spending_labels)\n",
    "\n",
    "# linear interpolieren\n",
    "data_edu_spending_int = data_edu_spending_int.interpolate(method=\"linear\", axis=1, limit_direction=\"both\")\n",
    "# data_edu_spending = data_edu_spending.dropna()\n",
    "\n",
    "# print(data_edu_spending_int)\n",
    "# Location spalte wieder hinzufügen\n",
    "data_edu_spending_int = pd.concat([data_edu_spending_labels[\"LOCATION\"], data_edu_spending_int]\n",
    "                            , ignore_index = False, axis=1)\n",
    "# print(data_edu_spending_int)\n",
    "\n",
    "# turn every year column into own column entry\n",
    "data_edu_spending_int = data_edu_spending_int.melt(id_vars='LOCATION', \n",
    "                                     var_name=\"TIME\", value_name=\"EDU_SPENDING\")\n",
    "\n",
    "data_edu_spending_int.TIME = data_edu_spending_int.TIME.apply(pd.to_numeric)\n",
    "\n",
    "data_edu_spending = data_edu_spending_int\n",
    "\n",
    "# data_edu_spending[data_edu_spending[\"EDU_SPENDING\"] == 0].head(100)\n",
    "data_edu_spending.info()\n",
    "data_edu_spending.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weltbankdaten\n",
    "https://databank.worldbank.org/reports.aspx?source=2&series=SE.XPD.SECO.PC.ZS#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_edu_spending = pd.read_csv(\"../data/gov_spending_per_student_of_GDP.csv\")\n",
    "\n",
    "data_edu_spending = data_edu_spending.replace({\"..\": np.nan})\n",
    "data_edu_spending.iloc[:, 28:54] = data_edu_spending.iloc[:, 28:54].apply(pd.to_numeric)\n",
    "\n",
    "data_edu_spending_int = data_edu_spending.iloc[:, 28:54]\n",
    "\n",
    "data_edu_spending = pd.concat([data_edu_spending.iloc[:, 3], data_edu_spending.iloc[:, 28:54]]\n",
    "                            , ignore_index = None, axis=1)\n",
    "data_edu_spending = data_edu_spending[[\"Country Code\"]]\n",
    "data_edu_spending = data_edu_spending.rename(columns={\"Country Code\": \"LOCATION\"})\n",
    "\n",
    "# data_edu_spending_int = \n",
    "\n",
    "# # Interpolation\n",
    "# print(data_edu_spending_int.info())\n",
    "data_edu_spending_int = data_edu_spending_int.interpolate(method=\"linear\", axis=1, limit_direction=\"both\")\n",
    "\n",
    "data_edu_spending = pd.concat([data_edu_spending[[\"LOCATION\"]], data_edu_spending_int]\n",
    "                            , ignore_index = None, axis=1)\n",
    "\n",
    "# turn every year column into own column entry\n",
    "data_edu_spending = data_edu_spending.melt(id_vars='LOCATION', \n",
    "                                     var_name=\"TIME\",value_name=\"EDU_SPENDING\")\n",
    "\n",
    "# jahre in einheitlichen float wert umwandeln\n",
    "mask = data_edu_spending[\"TIME\"].str.len() >= 5\n",
    "# alle time einträge die länger als 4 zeichen sind abschneiden\n",
    "data_edu_spending.loc[mask, [\"TIME\"]] = data_edu_spending[mask][\"TIME\"].str[0:5]\n",
    "# typecast; otherwise no merging possible\n",
    "data_edu_spending.TIME = data_edu_spending.TIME.apply(pd.to_numeric)\n",
    "\n",
    "# print(data_str[data_str[\"LOCATION\"] == \"DEU\"])\n",
    "data_edu_spending = data_edu_spending[data_edu_spending[\"TIME\"] >= 1999]\n",
    "data_edu_spending.info()\n",
    "data_edu_spending.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alkoholkonsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "data_alc = pd.read_csv('../data/alcohol_consumption.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_alc = data_alc[['LOCATION', 'TIME', 'Value']]\n",
    "#data_alc = data_alc[data_alc['TIME'] == YEAR]\n",
    "data_alc = data_alc.rename(columns = {'Value' : 'ALC_PC'})\n",
    "\n",
    "data_alc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corruption Perceptions Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_corruption = pd.read_csv('../data/cpi/cpi_2000_formatted.csv')\n",
    "data_corruption[\"TIME\"] = 2000\n",
    "# print(data_corruption.iloc[:, 1])\n",
    "# data_corruption[\"CPI\"] = data_corruption.iloc[:, 1]\n",
    "# data_corruption.drop([\"CPI Score 2000\"], axis=1)\n",
    "\n",
    "for year in range(2003, 2019)[0::3]:\n",
    "    print('../data/cpi/cpi_',year,'_formatted.csv')\n",
    "    data_corruption_next = pd.read_csv('../data/cpi/cpi_'+str(year)+'_formatted.csv')\n",
    "    data_corruption_next[\"TIME\"] = year\n",
    "    data_corruption = pd.concat([data_corruption, data_corruption_next], axis=0)\n",
    "    \n",
    "data_corruption.info()\n",
    "data_corruption.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sozialleistungsquote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv file\n",
    "data_social = pd.read_csv(\"../data/public_net_social_spending.csv\")\n",
    "\n",
    "# Select all available data after 2000\n",
    "# data_social = data_social[data_social[\"TIME\"] == 2015]\n",
    "# select only public net spending as percentage of gdp\n",
    "data_social = data_social[data_social[\"SUBJECT\"] == \"PUBNET\"]\n",
    "data_social = data_social[data_social[\"MEASURE\"] == \"PC_GDP\"]\n",
    "data_social = data_social[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "data_social = data_social.rename(columns={\"Value\": \"SOCIAL_EXP\"})\n",
    "# log Social expenses --> less heteroscedasticity and higher correlation\n",
    "# data_social[\"SOCIAL_EXP\"] = np.log(data_social[\"SOCIAL_EXP\"])\n",
    "# data_social = data_social.rename(columns={\"SOCIAL_EXP\": \"log(SOCIAL_EXP)\"})\n",
    "\n",
    "data_social.info()\n",
    "data_social.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internetzugang\n",
    "https://data.oecd.org/ict/internet-access.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_internet = pd.read_csv(\"../data/internet_access.csv\")\n",
    "\n",
    "data_internet = data_internet[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "data_internet = data_internet.rename(columns={\"Value\": \"INTERNET_PC\"})\n",
    "\n",
    "# In Zeitreihen verwandeln\n",
    "data_internet_int = data_internet.pivot_table(\"INTERNET_PC\", \"LOCATION\", \"TIME\")\n",
    "\n",
    "# wieder von pivot tabelle in df umwandeln\n",
    "data_internet_int.columns.name = None               #remove categories\n",
    "data_internet_int = data_internet_int.reset_index()                #index to columns\n",
    "\n",
    "# Spalten für fehlende Jahre hinzufügen\n",
    "nan_cols = pd.DataFrame(columns=[\"2000\", \"2001\", \"2002\", \"2003\", \"2004\"], dtype=\"float64\")\n",
    "\n",
    "data_internet_labels = data_internet_int\n",
    "# print(data_internet_labels)\n",
    "\n",
    "# linear interpolieren\n",
    "data_internet_int = data_internet_int.drop([\"LOCATION\"], axis=1) \n",
    "\n",
    "#nan cols hinzufügen\n",
    "data_internet_int = pd.concat([nan_cols, data_internet_int]\n",
    "                            , ignore_index = None, axis=1)\n",
    "\n",
    "data_internet_int = data_internet_int.interpolate(method=\"linear\", axis=1, limit_direction=\"both\")\n",
    "data_internet_int = pd.concat([data_internet_labels[\"LOCATION\"], data_internet_int]\n",
    "                            , ignore_index = False, axis=1)\n",
    "# print(data_internet_int)\n",
    "# turn every year column into own column entry\n",
    "data_internet_int = data_internet_int.melt(id_vars='LOCATION', \n",
    "                                     var_name=\"TIME\", value_name=\"INTERNET_PC\")\n",
    "\n",
    "data_internet_int.TIME = data_internet_int.TIME.apply(pd.to_numeric)\n",
    "data_internet = data_internet_int\n",
    "\n",
    "data_internet.info()\n",
    "data_internet.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anteil der 25-64 Jährigen mit tertiärer Bildung\n",
    "https://data.oecd.org/eduatt/adult-education-level.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_edu_try = pd.read_csv(\"../data/tertiary_edu.csv\")\n",
    "\n",
    "data_edu_try = data_edu_try[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "data_edu_try = data_edu_try.rename(columns={\"Value\": \"PCT_EDU_TRY\"})\n",
    "\n",
    "# In Zeitreihen verwandeln\n",
    "data_edu_try_int = data_edu_try.pivot_table(\"PCT_EDU_TRY\", \"LOCATION\", \"TIME\")\n",
    "\n",
    "# transform back to normal df\n",
    "data_edu_try_int.columns.name = None               #remove categories\n",
    "data_edu_try_int = data_edu_try_int.reset_index()                #index to columns\n",
    "\n",
    "data_edu_try_labels = data_edu_try_int\n",
    "\n",
    "# linear interpolieren\n",
    "data_edu_try_int = data_edu_try_int.drop([\"LOCATION\"], axis=1) \n",
    "\n",
    "data_edu_try_int = data_edu_try_int.interpolate(method=\"linear\", axis=1, limit_direction=\"both\")\n",
    "data_edu_try_int = pd.concat([data_edu_try_labels[\"LOCATION\"], data_edu_try_int]\n",
    "                            , ignore_index = False, axis=1)\n",
    "\n",
    "# turn every year column into own column entry\n",
    "data_edu_try_int = data_edu_try_int.melt(id_vars='LOCATION', \n",
    "                                     var_name=\"TIME\", value_name=\"PCT_EDU_TRY\")\n",
    "data_edu_try = data_edu_try_int\n",
    "\n",
    "\n",
    "\n",
    "data_edu_try.info()\n",
    "data_edu_try.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patentanmeldungen\n",
    "https://data.oecd.org/rd/triadic-patent-families.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_patents = pd.read_csv(\"../data/patents.csv\")\n",
    "\n",
    "data_patents = data_patents[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "data_patents = data_patents.rename(columns={\"Value\": \"PATENTS\"})\n",
    "\n",
    "data_patents.info()\n",
    "data_patents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing overcrowding\n",
    "https://data.oecd.org/inequality/housing-overcrowding.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_housing = pd.read_csv(\"../data/housing_overcrowding.csv\")\n",
    "\n",
    "data_housing = data_housing[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "data_housing = data_housing.rename(columns={\"Value\": \"HOUSING\"})\n",
    "\n",
    "data_housing.info()\n",
    "data_housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poverty rate\n",
    "https://data.oecd.org/inequality/poverty-rate.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_poverty = pd.read_csv(\"../data/poverty_rate.csv\")\n",
    "\n",
    "data_poverty = data_poverty[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "data_poverty = data_poverty.rename(columns={\"Value\": \"POVERTY\"})\n",
    "\n",
    "data_poverty.info()\n",
    "data_poverty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment rate\n",
    "https://data.oecd.org/emp/employment-rate.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_employment = pd.read_csv(\"../data/employment_rate.csv\")\n",
    "\n",
    "data_employment = data_employment[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "data_employment = data_employment.rename(columns={\"Value\": \"EMPLOYMENT\"})\n",
    "\n",
    "data_employment.info()\n",
    "data_employment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early marriage: Nur für 2019 daten\n",
    "https://data.oecd.org/inequality/discriminatory-family-code.htm#indicator-chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_early_marriage = pd.read_csv(\"../data/child_marriage.csv\")\n",
    "\n",
    "data_early_marriage = data_early_marriage[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "data_early_marriage = data_early_marriage.rename(columns={\"Value\": \"EARLY_MARRIAGE\"})\n",
    "\n",
    "data_early_marriage.info()\n",
    "data_early_marriage.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### teaching hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_teaching_hrs = pd.read_csv(\"../data/teaching_hours.csv\")\n",
    "\n",
    "data_teaching_hrs = data_teaching_hrs[data_teaching_hrs[\"SUBJECT\"] == \"LOWSRY\"]\n",
    "data_teaching_hrs = data_teaching_hrs[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "data_teaching_hrs = data_teaching_hrs.rename(columns={\"Value\": \"TEACHINGHRS\"})\n",
    "\n",
    "data_teaching_hrs.info()\n",
    "data_teaching_hrs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gesundsheitsausgaben\n",
    "https://data.oecd.org/healthres/health-spending.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_health_spending_PC = pd.read_csv(\"../data/health_spending_PC.csv\")\n",
    "\n",
    "data_health_spending_PC = data_health_spending_PC[data_health_spending_PC[\"SUBJECT\"] == \"TOT\"]\n",
    "data_health_spending_PC = data_health_spending_PC[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "data_health_spending_PC = data_health_spending_PC.rename(columns={\"Value\": \"HEALTH_SPENDING_PC\"})\n",
    "\n",
    "# data_health_spending_PC = data_health_spending_PC[data_health_spending_PC[\"LOCATION\"] == \"AUS\"]\n",
    "data_health_spending_PC.info()\n",
    "data_health_spending_PC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_health_spending_PCT_GDP = pd.read_csv(\"../data/health_spending_PC_GDP.csv\")\n",
    "\n",
    "data_health_spending_PCT_GDP = data_health_spending_PCT_GDP[data_health_spending_PCT_GDP[\"SUBJECT\"] == \"TOT\"]\n",
    "data_health_spending_PCT_GDP = data_health_spending_PCT_GDP[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "data_health_spending_PCT_GDP = data_health_spending_PCT_GDP.rename(columns={\"Value\": \"HEALTH_SPENDING_PCT_GDP\"})\n",
    "\n",
    "data_health_spending_PCT_GDP.info()\n",
    "data_health_spending_PCT_GDP.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human Development Index\n",
    "http://hdr.undp.org/en/indicators/137506#\n",
    "https://ourworldindata.org/human-development-index (Hier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#import csv file\n",
    "data_hdi = pd.read_csv(\"../data/hdi.csv\")\n",
    "\n",
    "# Select all only the specified year\n",
    "data_hdi = data_hdi[[\"Code\", \"Year\", \"Human Development Index (UNDP)\"]]\n",
    "data_hdi = data_hdi.rename(columns={\"Code\": \"LOCATION\", \"Year\": \"TIME\", \"Human Development Index (UNDP)\": \"HDI\"})\n",
    "data_hdi = data_hdi[data_hdi[\"TIME\"] >= 1999]\n",
    "\n",
    "# In Zeitreihen verwandeln\n",
    "data_hdi_p = data_hdi.pivot_table(\"HDI\", \"LOCATION\", \"TIME\")\n",
    "data_hdi_p[\"2018\"] = np.nan\n",
    "\n",
    "# transform back to normal df\n",
    "data_hdi_p.columns.name = None               #remove categories\n",
    "data_hdi_p = data_hdi_p.reset_index()                #index to columns\n",
    "\n",
    "data_hdi_labels = data_hdi_p\n",
    "# print(data_hdi_p)\n",
    "\n",
    "# linear interpolieren\n",
    "data_hdi_p = data_hdi_p.drop([\"LOCATION\"], axis=1) \n",
    "data_hdi_p = data_hdi_p.interpolate(method=\"linear\", axis=1, limit_direction=\"both\")\n",
    "data_hdi_p = pd.concat([data_hdi_labels[\"LOCATION\"], data_hdi_p]\n",
    "                            , ignore_index = False, axis=1)\n",
    "\n",
    "# print(data_hdi)\n",
    "# print(data_hdi_p)\n",
    "# turn every year column into own column entry\n",
    "data_hdi_p = data_hdi_p.melt(id_vars='LOCATION', \n",
    "                                     var_name=\"TIME\", value_name=\"HDI\")\n",
    "\n",
    "# typecast; otherwise no merging possible\n",
    "data_hdi_p.TIME = data_hdi_p.TIME.apply(pd.to_numeric)\n",
    "\n",
    "# print(data_hdi_p)\n",
    "\n",
    "data_hdi = data_hdi_p\n",
    "# print(data_hdi[data_hdi[\"TIME\"] == 2017])\n",
    "\n",
    "data_hdi.info()\n",
    "data_hdi.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homicide rate\n",
    "- Worldbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import csv file\n",
    "data_homicide = pd.read_csv(\"../data/homicide_rate.csv\")\n",
    "\n",
    "data_homicide_int = data_homicide.iloc[:, 34:63]\n",
    "\n",
    "data_homicide = data_homicide[[\"Country Code\"]]\n",
    "data_homicide = data_homicide.rename(columns={\"Country Code\": \"LOCATION\"})\n",
    "\n",
    "\n",
    "# Interpolation\n",
    "data_homicide_int = data_homicide_int.interpolate(method=\"linear\", axis=1, limit_direction=\"both\")\n",
    "\n",
    "data_homicide = pd.concat([data_homicide[[\"LOCATION\"]], data_homicide_int]\n",
    "                            , ignore_index = None, axis=1)\n",
    "# # turn every year column into own column entry\n",
    "data_homicide = data_homicide.melt(id_vars='LOCATION', \n",
    "                                     var_name=\"TIME\",value_name=\"HOMICIDES\")\n",
    "# typecast; otherwise no merging possible\n",
    "data_homicide.TIME = data_homicide.TIME.apply(pd.to_numeric)\n",
    "\n",
    "# data_homicide_int.info()\n",
    "# data_homicide_int.head()\n",
    "data_homicide.info()\n",
    "data_homicide.head()\n",
    "# print(data_homicide[data_homicide[\"HOMICIDES\"] == 0])\n",
    "# data_homicide[data_homicide[\"HOMICIDES\"] == 0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mergen aller Daten in eine große Tabelle (Outer Join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_all = data_pisa_math.merge(data_pisa_read, how=\"outer\", left_on = ['LOCATION', 'TIME', 'SUBJECT'], \n",
    "                                right_on = ['LOCATION', 'TIME', 'SUBJECT'])\n",
    "data_all = data_all.rename(columns={\"Value_x\": \"PISA Math\", \"Value_y\": \"PISA Read\"})\n",
    "\n",
    "data_all = data_all.merge(data_pisa_science, how=\"outer\", left_on = ['LOCATION', 'TIME', 'SUBJECT'], \n",
    "                                right_on = ['LOCATION', 'TIME', 'SUBJECT'])\n",
    "data_all = data_all.rename(columns={\"Value\": \"PISA Science\"})\n",
    "\n",
    "data_all = data_all.merge(data_gini, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "                                right_on = ['LOCATION', 'TIME'])\n",
    "data_all = data_all.merge(data_migration, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "                                right_on = ['LOCATION', 'TIME'])\n",
    "data_all = data_all.merge(data_str, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "                                right_on = ['LOCATION', 'TIME'])\n",
    "data_all = data_all.merge(data_gdp, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "                                right_on = ['LOCATION', 'TIME'])\n",
    "data_all = data_all.merge(data_edu_spending, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "                                right_on = ['LOCATION', 'TIME'])\n",
    "data_all = data_all.merge(data_corruption, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "                                right_on = ['LOCATION', 'TIME'])\n",
    "data_all = data_all.merge(data_alc, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "                                right_on = ['LOCATION', 'TIME'])\n",
    "# data_all = data_all.merge(data_social, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "#                                 right_on = ['LOCATION', 'TIME'])\n",
    "data_all = data_all.merge(data_internet, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "                                right_on = ['LOCATION', 'TIME'])\n",
    "data_all = data_all.merge(data_edu_try, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "                                right_on = ['LOCATION', 'TIME'])\n",
    "# data_all = data_all.merge(data_health_spending_PCT_GDP, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "#                                 right_on = ['LOCATION', 'TIME'])\n",
    "# data_all = data_all.merge(data_health_spending_PC, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "#                                 right_on = ['LOCATION', 'TIME'])\n",
    "# data_all = data_all.merge(data_patents, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "#                                 right_on = ['LOCATION', 'TIME'])\n",
    "# data_all = data_all.merge(data_housing, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "#                                 right_on = ['LOCATION', 'TIME'])\n",
    "# data_all = data_all.merge(data_poverty, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "#                                 right_on = ['LOCATION', 'TIME'])\n",
    "# data_all = data_all.merge(data_teaching_hrs, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "#                                 right_on = ['LOCATION', 'TIME'])\n",
    "# data_all = data_all.merge(data_employment, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "#                                 right_on = ['LOCATION', 'TIME'])\n",
    "# data_all = data_all.merge(data_hdi, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "#                                 right_on = ['LOCATION', 'TIME'])\n",
    "data_all = data_all.merge(data_homicide, how=\"outer\", left_on = ['LOCATION', 'TIME'], \n",
    "                                right_on = ['LOCATION', 'TIME'])\n",
    "# delete OECD Avergae \n",
    "data_all = data_all[data_all[\"LOCATION\"] != \"OAVG\"]\n",
    "# delete Macau and taiwan, only macro data for china\n",
    "data_all = data_all[data_all[\"LOCATION\"] != \"MAC\"] \n",
    "data_all = data_all[data_all[\"LOCATION\"] != \"TWN\"]\n",
    "\n",
    "# ein jahr auswählen\n",
    "# data_all = data_all[data_all[\"TIME\"] == 2015]\n",
    "\n",
    "data_all = data_all[data_all[\"SUBJECT\"] == \"TOT\"]\n",
    "\n",
    "data_all.info()\n",
    "data_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.info()\n",
    "data_all.to_csv('../data/all_nan.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_impute(data, year, k):\n",
    "    # alle daten außer year\n",
    "    data_imputed = data[data[\"TIME\"] != year]\n",
    "    # nur daten für year\n",
    "    data_imputed_year = data[data[\"TIME\"] == year]\n",
    "    data_imputed_labels = data_imputed_year\n",
    "    data_imputed_year = data_imputed_year.drop([\"SUBJECT\", \"LOCATION\", \"TIME\"], axis=1)\n",
    "   \n",
    "    # zu erklärende variablen auch entfernen\n",
    "    data_imputed_year = data_imputed_year.drop([\"PISA Math\", \"PISA Read\", \"PISA Science\"], axis=1)\n",
    "    \n",
    "#     print(data_imputed_year)\n",
    "#     print(data_imputed_labels)\n",
    "    \n",
    "    # Normalisierung für Imputation\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    data_imputed_year = pd.DataFrame(scaler.fit_transform(data_imputed_year),\n",
    "                                columns = data_imputed_year.columns)\n",
    "    \n",
    "    # Imputation\n",
    "    from sklearn.impute import KNNImputer\n",
    "    imputer = KNNImputer(n_neighbors = k)\n",
    "    data_imputed_year = pd.DataFrame(imputer.fit_transform(data_imputed_year),\n",
    "                                    columns = data_imputed_year.columns)\n",
    "\n",
    "    # transform data back to original scale\n",
    "    data_imputed_year =  pd.DataFrame(scaler.inverse_transform(data_imputed_year),\n",
    "                                     columns = data_imputed_year.columns)\n",
    "\n",
    "    # vorher entfernte relevante spalten wieder hinzufügen\n",
    "    data_imputed_labels = data_imputed_labels.reset_index(drop=True)\n",
    "    data_imputed_year = data_imputed_year.reset_index(drop=True)\n",
    "\n",
    "    data_imputed_year = pd.concat([data_imputed_labels[[\"SUBJECT\", \"LOCATION\", \"TIME\", \"PISA Math\", \"PISA Read\", \"PISA Science\"]], data_imputed_year]\n",
    "                                , ignore_index = None, axis=1)\n",
    "#     print(data_imputed)\n",
    "\n",
    "    data_imputed = data_imputed.append(data_imputed_year)\n",
    "#     print(data_imputed[data_imputed[\"TIME\"] == 2015])\n",
    "#     print(data_imputed[data_imputed[\"TIME\"] == 2012])\n",
    "    \n",
    "    return data_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "years = list(range(2000, 2019))\n",
    "# years[0::3]\n",
    "data_all_imputed = data_all\n",
    "for y in years[0::3]:\n",
    "    print(\"################################# Imputing \", y, \"#################\")\n",
    "    data_all_imputed = knn_impute(data_all_imputed, y, 2)\n",
    "    print(\"#################################\", y, \" imputed #################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithmieren bei den passenden Regressoren\n",
    "Logarithmiert wurden alle Regressoren bei denen durch diese Transformation\n",
    "- die Korrelation (= der lineare Zusammenhang) deutlich erhöht werden konnte\n",
    "- starke Heteroskedastie vermieden werden konnte\n",
    "- stark gestauchte verteilung --> bessere Verteilung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(data_all_imputed)\n",
    "\n",
    "data_all_imputed[\"log(MIGRANTS)\"] = np.log(data_all_imputed[\"MIGRANTS\"])\n",
    "data_all_imputed = data_all_imputed.drop([\"MIGRANTS\"], axis = 1)\n",
    "\n",
    "data_all[\"log(MIGRANTS)\"] = np.log(data_all[\"MIGRANTS\"])\n",
    "data_all = data_all.drop([\"MIGRANTS\"], axis = 1)\n",
    "\n",
    "# print(data_all_imputed)\n",
    "data_all_imputed[\"log(GDP)\"] = np.log(data_all_imputed[\"GDP\"])\n",
    "data_all_imputed = data_all_imputed.drop([\"GDP\"], axis = 1)\n",
    "\n",
    "data_all[\"log(GDP)\"] = np.log(data_all[\"GDP\"])\n",
    "data_all = data_all.drop([\"GDP\"], axis = 1)\n",
    "\n",
    "data_all_imputed[\"log(EDU_SPENDING)\"] = np.log(data_all_imputed[\"EDU_SPENDING\"])\n",
    "data_all_imputed = data_all_imputed.drop([\"EDU_SPENDING\"], axis = 1)\n",
    "\n",
    "data_all[\"log(EDU_SPENDING)\"] = np.log(data_all[\"EDU_SPENDING\"])\n",
    "data_all = data_all.drop([\"EDU_SPENDING\"], axis = 1)\n",
    "\n",
    "# data_all_imputed[\"log(SOCIAL_EXP)\"] = np.log(data_all_imputed[\"SOCIAL_EXP\"])\n",
    "# data_all_imputed = data_all_imputed.drop([\"SOCIAL_EXP\"], axis = 1)\n",
    "\n",
    "# data_all[\"log(SOCIAL_EXP)\"] = np.log(data_all[\"SOCIAL_EXP\"])\n",
    "# data_all = data_all.drop([\"SOCIAL_EXP\"], axis = 1)\n",
    "\n",
    "data_all_imputed[\"log(PCT_EDU_TRY)\"] = np.log(data_all_imputed[\"PCT_EDU_TRY\"])\n",
    "data_all_imputed = data_all_imputed.drop([\"PCT_EDU_TRY\"], axis = 1)\n",
    "\n",
    "data_all[\"log(PCT_EDU_TRY)\"] = np.log(data_all[\"PCT_EDU_TRY\"])\n",
    "data_all = data_all.drop([\"PCT_EDU_TRY\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemeinsame Korrelationsanalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "r_all = data_all_imputed[[\"PISA Math\", \"PISA Read\", \"PISA Science\", \"GINI\", \"log(GDP)\", \"CPI\", \"log(PCT_EDU_TRY)\", \"log(MIGRANTS)\", \"log(EDU_SPENDING)\", \"ALC_PC\", \"HOMICIDES\", \"INTERNET_PC\", \"STR_SRY\"]].corr().round(decimals = 2).abs()\n",
    "# print(r_all)\n",
    "#sns.heatmap(r_all, cmap=\"Blues\", vmax = 0.8, vmin = 0.2, annot = True)\n",
    "sns.heatmap(r_all, cmap=\"Blues\", robust=True, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/the-use-of-knn-for-missing-values-cf33d935c637\n",
    "https://towardsdatascience.com/how-to-find-the-optimal-value-of-k-in-knn-35d936e554eb\n",
    "Veschieden starke Korrelation abhängig von der Wahl von k:\n",
    "- geringes k: anfällig für Ausreißer, da einzelne Nachbarn großen Einfluss haben\n",
    "- hohes k: alle fehlenden Zellen werden mit sehr ähnlichen Werten gefüllt -> Gruppengrenzen verschwimmen\n",
    "- für k=n entspricht kNN-Imputation der einfachen Imputation mit dem arithmetischen Mittel\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Anzahl der Nachbarn k</th><th>Korrelation von PISA Math und GINI</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td><td>0,74</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td><td>0,76</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3</td><td>0,73</td>\n",
    "    </tr>    \n",
    "    <tr>\n",
    "        <td>4</td><td>0,71</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>5</td><td>0,70</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>7</td><td>0,69</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>9</td><td>0,68</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>15</td><td>0,66</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>30</td><td>0,62</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>50</td><td>0.62</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>100</td><td>0,62</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufteilen in Math, Read, Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_math = data_all_imputed.drop([\"PISA Read\", \"PISA Science\"], axis=1)\n",
    "data_math = data_math.dropna()\n",
    "data_math.info()\n",
    "data_math.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_read = data_all_imputed.drop([\"PISA Math\", \"PISA Science\"], axis=1)\n",
    "data_read = data_read.dropna()\n",
    "data_read.info()\n",
    "data_read.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_science = data_all_imputed.drop([\"PISA Read\", \"PISA Math\"], axis=1)\n",
    "data_science = data_science.dropna()\n",
    "data_science.info()\n",
    "data_science.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log(GDP): Evaluation der kNN-Imputation: Vergleich mit mean-Imputation und gar keiner Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- Imputation ----------------------\n",
    "x = data_math[\"log(GDP)\"]\n",
    "# x = np.exp(x)\n",
    "y = data_math[\"PISA Math\"]\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('log(GDP)')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# --------------- Imputation mit mean ---------------------\n",
    "x = data_all[\"log(GDP)\"].fillna(data_all[\"log(GDP)\"].mean())\n",
    "y = data_all[\"PISA Math\"].fillna(data_all[\"PISA Math\"].mean())\n",
    "# y = np.log(y)\n",
    "\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('log(GDP)')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# --------------- No Imputation ---------------------\n",
    "data = data_all.dropna()\n",
    "x = data[\"log(GDP)\"]\n",
    "y = data[\"PISA Math\"]\n",
    "# y = np.log(y)\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('log(GDP)')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STR_SRY: Evaluation der kNN-Imputation: Vergleich mit mean-Imputation und gar keiner Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- Imputation ----------------------\n",
    "x = data_math[\"STR_SRY\"]\n",
    "# x = np.log(x)\n",
    "y = data_math[\"PISA Math\"]\n",
    "# y = np.log(y)\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('STR_SRY')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# --------------- Imputation mit mean ---------------------\n",
    "x = data_all[\"STR_SRY\"].fillna(data_all[\"STR_SRY\"].mean())\n",
    "# x = np.log(x)\n",
    "y = data_all[\"PISA Math\"].fillna(data_all[\"PISA Math\"].mean())\n",
    "# y = np.log(y)\n",
    "\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('STR_SRY')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# --------------- No Imputation ---------------------\n",
    "data = data_all.dropna()\n",
    "x = data[\"STR_SRY\"]\n",
    "# x = np.log(x)\n",
    "y = data[\"PISA Math\"]\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('STR_SRY')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log(MIGRANTS): Evaluation der kNN-Imputation: Vergleich mit mean-Imputation und gar keiner Imputation\n",
    "- heteroskedastische Züge im Scatter-Plot zu erkennen --> log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- Imputation ----------------------\n",
    "x = data_math[\"log(MIGRANTS)\"]\n",
    "# x = np.exp(x)\n",
    "y = data_math[\"PISA Math\"]\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "# fig, ax = plt.subplots(figsize=(10, 6))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('log(MIGRANTS)')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# --------------- Imputation mit mean ---------------------\n",
    "x = data_all[\"log(MIGRANTS)\"].fillna(data_all[\"log(MIGRANTS)\"].mean())\n",
    "# x = np.log(x)\n",
    "y = data_all[\"PISA Math\"].fillna(data_all[\"PISA Math\"].mean())\n",
    "# y = np.log(y)\n",
    "\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('log(MIGRANTS)')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# --------------- No Imputation ---------------------\n",
    "data = data_all.dropna()\n",
    "x = data[\"log(MIGRANTS)\"]\n",
    "# x = np.log(x)\n",
    "y = data[\"PISA Math\"]\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('log(MIGRANTS)')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GINI: Evaluation der kNN-Imputation: Vergleich mit mean-Imputation und gar keiner Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-------------------- Imputation ----------------------\n",
    "x = data_math[\"GINI\"]\n",
    "# x = np.log(x)\n",
    "# x = np.sqrt(x)\n",
    "y = data_math[\"PISA Math\"]\n",
    "# y = np.log(y)\n",
    "# y = np.sqrt(y\n",
    "# data_math.info()\n",
    "\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('GINI')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "# plt.title('Gini kNN-Imputation')\n",
    "plt.show()\n",
    "\n",
    "# --------------- Imputation mit mean ---------------------\n",
    "data_mean = data_all\n",
    "data_mean[\"GINI\"] = data_all[\"GINI\"].fillna(data_all[\"GINI\"].mean())\n",
    "data_mean = data_mean[pd.notnull(data_all[\"PISA Math\"])]\n",
    "x = data_mean[\"GINI\"]\n",
    "# x = np.log(x)\n",
    "y = data_mean[\"PISA Math\"]\n",
    "# y = np.log(y)\n",
    "\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('GINI')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "# plt.title('Gini Mean-Imputation')\n",
    "plt.show()\n",
    "\n",
    "# --------------- No Imputation ---------------------\n",
    "data = data_all.dropna()\n",
    "# data.info()\n",
    "x = data[\"GINI\"]\n",
    "# x = np.log(x)\n",
    "y = data[\"PISA Math\"]\n",
    "# y = np.log(y)\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('GINI')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "# plt.title('Gini keine Imputation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   log(EDU_SPENDING): Evaluation der kNN-Imputation: Vergleich mit mean-Imputation und gar keiner Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- Imputation ----------------------\n",
    "x = data_math[\"log(EDU_SPENDING)\"]\n",
    "# x = np.sqrt(x)\n",
    "x = np.exp(x)\n",
    "y = data_math[\"PISA Math\"]\n",
    "# y = np.log(y)\n",
    "# y = np.sqrt(y)\n",
    "\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('log(EDU_SPENDING)')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# --------------- Imputation mit mean ---------------------\n",
    "x = data_all[\"log(EDU_SPENDING)\"].fillna(data_all[\"log(EDU_SPENDING)\"].mean())\n",
    "# x = np.log(x)\n",
    "y = data_all[\"PISA Math\"].fillna(data_all[\"PISA Math\"].mean())\n",
    "# y = np.log(y)\n",
    "\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('log(EDU_SPENDING)')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# --------------- No Imputation ---------------------\n",
    "data = data_all.dropna()\n",
    "x = data[\"log(EDU_SPENDING)\"]\n",
    "# x = np.log(x)\n",
    "y = data[\"PISA Math\"]\n",
    "# y = np.log(y)\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('log(EDU_SPENDING)')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alcohol consumption per capita: Evaluation der kNN-Imputation: Vergleich mit mean-Imputation und gar keiner Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- Imputation ----------------------\n",
    "x = data_math[\"ALC_PC\"]\n",
    "# x = np.log(x)\n",
    "# x = np.sqrt(x)\n",
    "y = data_math[\"PISA Math\"]\n",
    "# y = np.log(y)\n",
    "# y = np.sqrt(y)\n",
    "\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('ALC_PC')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# --------------- Imputation mit mean ---------------------\n",
    "x = data_all[\"ALC_PC\"].fillna(data_all[\"ALC_PC\"].mean())\n",
    "# x = np.log(x)\n",
    "y = data_all[\"PISA Math\"].fillna(data_all[\"PISA Math\"].mean())\n",
    "# y = np.log(y)\n",
    "\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('ALC_PC')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# --------------- No Imputation ---------------------\n",
    "data = data_all.dropna()\n",
    "x = data[\"ALC_PC\"]\n",
    "# x = np.log(x)\n",
    "y = data[\"PISA Math\"]\n",
    "# y = np.log(y)\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('ALC_PC')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social_Expenses_PCT: Evaluation der kNN-Imputation: Vergleich mit mean-Imputation und gar keiner Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #-------------------- Imputation ----------------------\n",
    "# x = data_math[\"log(SOCIAL_EXP)\"]\n",
    "# # x = np.log(x)\n",
    "# # x = np.sqrt(x)\n",
    "# y = data_math[\"PISA Math\"]\n",
    "# # y = np.log(y)\n",
    "# # y = np.sqrt(y)\n",
    "\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('log(SOCIAL_EXP)')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()\n",
    "\n",
    "# # --------------- Imputation mit mean ---------------------\n",
    "# x = data_all[\"log(SOCIAL_EXP)\"].fillna(data_all[\"log(SOCIAL_EXP)\"].mean())\n",
    "# # x = np.log(x)\n",
    "# y = data_all[\"PISA Math\"].fillna(data_all[\"PISA Math\"].mean())\n",
    "# # y = np.log(y)\n",
    "\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('SOCIAL_EXP')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()\n",
    "\n",
    "# # --------------- No Imputation ---------------------\n",
    "# data = data_all.dropna()\n",
    "# x = data[\"log(SOCIAL_EXP)\"]\n",
    "# # x = np.log(x)\n",
    "# y = data[\"PISA Math\"]\n",
    "# # y = np.log(y)\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('log(SOCIAL_EXP)')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTERNET_PC: Evaluation der kNN-Imputation: Vergleich mit mean-Imputation und gar keiner Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- Imputation ----------------------\n",
    "x = data_math[\"INTERNET_PC\"]\n",
    "# x = np.log(x)\n",
    "# x = np.sqrt(x)\n",
    "y = data_math[\"PISA Math\"]\n",
    "# y = np.log(y)\n",
    "# y = np.sqrt(y)\n",
    "\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('INTERNET_PC')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# --------------- Imputation mit mean ---------------------\n",
    "x = data_all[\"INTERNET_PC\"].fillna(data_all[\"INTERNET_PC\"].mean())\n",
    "# x = np.log(x)\n",
    "y = data_all[\"PISA Math\"].fillna(data_all[\"PISA Math\"].mean())\n",
    "# y = np.log(y)\n",
    "\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('INTERNET_PC')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# --------------- No Imputation ---------------------\n",
    "data = data_all.dropna()\n",
    "x = data[\"INTERNET_PC\"]\n",
    "# x = np.log(x)\n",
    "y = data[\"PISA Math\"]\n",
    "# y = np.log(y)\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('INTERNET_PC')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PATENTS: Evaluation der kNN-Imputation: Vergleich mit mean-Imputation und gar keiner Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #-------------------- Imputation ----------------------\n",
    "# x = data_math[\"PATENTS\"]\n",
    "# x = np.log(x)\n",
    "# # x = np.sqrt(x)\n",
    "# y = data_math[\"PISA Math\"]\n",
    "# # y = np.log(y)\n",
    "# # y = np.sqrt(y)\n",
    "\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('PATENTS')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()\n",
    "\n",
    "# # --------------- Imputation mit mean ---------------------\n",
    "# x = data_all[\"PATENTS\"].fillna(data_all[\"PATENTS\"].mean())\n",
    "# # x = np.log(x)\n",
    "# y = data_all[\"PISA Math\"].fillna(data_all[\"PISA Math\"].mean())\n",
    "# # y = np.log(y)\n",
    "\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('PATENTS')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()\n",
    "\n",
    "# # --------------- No Imputation ---------------------\n",
    "# data = data_all.dropna()\n",
    "# x = data[\"PATENTS\"]\n",
    "# # x = np.log(x)\n",
    "# y = data[\"PISA Math\"]\n",
    "# # y = np.log(y)\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('PATENTS')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOUSING: Evaluation der kNN-Imputation: Vergleich mit mean-Imputation und gar keiner Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #-------------------- Imputation ----------------------\n",
    "# x = data_math[\"HOUSING\"]\n",
    "# # x = np.log(x)\n",
    "# # x = np.sqrt(x)\n",
    "# y = data_math[\"PISA Math\"]\n",
    "# # y = np.log(y)\n",
    "# # y = np.sqrt(y)\n",
    "\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('HOUSING')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()\n",
    "\n",
    "# # --------------- Imputation mit mean ---------------------\n",
    "# x = data_all[\"HOUSING\"].fillna(data_all[\"HOUSING\"].mean())\n",
    "# # x = np.log(x)\n",
    "# y = data_all[\"PISA Math\"].fillna(data_all[\"PISA Math\"].mean())\n",
    "# # y = np.log(y)\n",
    "\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('HOUSING')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()\n",
    "\n",
    "# # --------------- No Imputation ---------------------\n",
    "# data = data_all.dropna()\n",
    "# x = data[\"HOUSING\"]\n",
    "# # x = np.log(x)\n",
    "# y = data[\"PISA Math\"]\n",
    "# # y = np.log(y)\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('HOUSING')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POVERTY: Evaluation der kNN-Imputation: Vergleich mit mean-Imputation und gar keiner Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #-------------------- Imputation ----------------------\n",
    "# x = data_math[\"POVERTY\"]\n",
    "# # x = np.log(x)\n",
    "# # x = 1/x\n",
    "# # x = np.log(x)\n",
    "# # x = np.sqrt(x)\n",
    "# y = data_math[\"PISA Math\"]\n",
    "# # y = np.log(y)\n",
    "# # y = np.sqrt(y)\n",
    "\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('POVERTY')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()\n",
    "\n",
    "# # --------------- Imputation mit mean ---------------------\n",
    "# x = data_all[\"POVERTY\"].fillna(data_all[\"POVERTY\"].mean())\n",
    "# # x = np.log(x)\n",
    "# y = data_all[\"PISA Math\"].fillna(data_all[\"PISA Math\"].mean())\n",
    "# # y = np.log(y)\n",
    "\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('POVERTY')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()\n",
    "\n",
    "# # --------------- No Imputation ---------------------\n",
    "# data = data_all.dropna()\n",
    "# x = data[\"POVERTY\"]\n",
    "# # x = np.log(x)\n",
    "# y = data[\"PISA Math\"]\n",
    "# # y = np.log(y)\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('POVERTY')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment rate: Evaluation der kNN-Imputation: Vergleich mit mean-Imputation und gar keiner Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #-------------------- Imputation ----------------------\n",
    "# x = data_math[\"EMPLOYMENT\"]\n",
    "# # x = np.log(x)\n",
    "# # x = 1/x\n",
    "# # x = np.log(x)\n",
    "# # x = np.sqrt(x)\n",
    "# y = data_math[\"PISA Math\"]\n",
    "# # y = np.log(y)\n",
    "# # y = np.sqrt(y)\n",
    "\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('EMPLOYMENT')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()\n",
    "\n",
    "# # --------------- Imputation mit mean ---------------------\n",
    "# x = data_all[\"EMPLOYMENT\"].fillna(data_all[\"EMPLOYMENT\"].mean())\n",
    "# # x = np.log(x)\n",
    "# y = data_all[\"PISA Math\"].fillna(data_all[\"PISA Math\"].mean())\n",
    "# # y = np.log(y)\n",
    "\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('EMPLOYMENT')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()\n",
    "\n",
    "# # --------------- No Imputation ---------------------\n",
    "# data = data_all.dropna()\n",
    "# x = data[\"EMPLOYMENT\"]\n",
    "# # x = np.log(x)\n",
    "# y = data[\"PISA Math\"]\n",
    "# # y = np.log(y)\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('EMPLOYMENT')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teaching hours LOWSRY: Evaluation der kNN-Imputation: Vergleich mit mean-Imputation und gar keiner Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #-------------------- Imputation ----------------------\n",
    "# x = data_math[\"TEACHINGHRS\"]\n",
    "# # x=x**2\n",
    "# # x = np.log(x)\n",
    "# # x = 1/x\n",
    "# # x = np.log(x)\n",
    "# # x = np.sqrt(x)\n",
    "# # x = np.exp(x)\n",
    "# y = data_math[\"PISA Math\"]\n",
    "# # y = np.log(y)\n",
    "# # y = np.sqrt(y)\n",
    "\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('TEACHINGHRS')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()\n",
    "\n",
    "# # --------------- Imputation mit mean ---------------------\n",
    "# x = data_all[\"TEACHINGHRS\"].fillna(data_all[\"TEACHINGHRS\"].mean())\n",
    "# # x = np.log(x)\n",
    "# y = data_all[\"PISA Math\"].fillna(data_all[\"PISA Math\"].mean())\n",
    "# # y = np.log(y)\n",
    "\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('TEACHINGHRS')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()\n",
    "\n",
    "# # --------------- No Imputation ---------------------\n",
    "# data = data_all.dropna()\n",
    "# x = data[\"TEACHINGHRS\"]\n",
    "# # x = np.log(x)\n",
    "# y = data[\"PISA Math\"]\n",
    "# # y = np.log(y)\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('TEACHINGHRS')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDI: Evaluation der kNN-Imputation: Vergleich mit mean-Imputation und gar keiner Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #-------------------- Imputation ----------------------\n",
    "# x = data_math[\"HDI\"]\n",
    "# # x = np.log(x)\n",
    "# # x = np.sqrt(x)\n",
    "# y = data_math[\"PISA Math\"]\n",
    "# # y = np.log(y)\n",
    "# # y = np.sqrt(y)\n",
    "\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('HDI')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()\n",
    "\n",
    "# # --------------- Imputation mit mean ---------------------\n",
    "# x = data_all[\"HDI\"].fillna(data_all[\"HDI\"].mean())\n",
    "# # x = np.log(x)\n",
    "# y = data_all[\"PISA Math\"].fillna(data_all[\"PISA Math\"].mean())\n",
    "# # y = np.log(y)\n",
    "\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('HDI')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()\n",
    "\n",
    "# # --------------- No Imputation ---------------------\n",
    "# data = data_all.dropna()\n",
    "# x = data[\"HDI\"]\n",
    "# # x = np.log(x)\n",
    "# y = data[\"PISA Math\"]\n",
    "# # y = np.log(y)\n",
    "# #plt.plot(x, y, \"o\", color=\"blue\")\n",
    "# r_gini = np.corrcoef(x, y)\n",
    "# print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "# slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "# line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "# #line\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "# ax.plot(x, intercept + slope * x, label=line)\n",
    "# ax.set_xlabel('HDI')\n",
    "# ax.set_ylabel('PISA_MATH')\n",
    "# ax.legend(facecolor='white')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOMICIDES: Evaluation der kNN-Imputation: Vergleich mit mean-Imputation und gar keiner Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-------------------- Imputation ----------------------\n",
    "x = data_math[\"HOMICIDES\"]\n",
    "print(data_math[data_math[\"HOMICIDES\"] == 0])\n",
    "# x = x**2\n",
    "# x = np.sqrt(x)\n",
    "y = data_math[\"PISA Math\"]\n",
    "# y = np.log(y)\n",
    "# y = np.sqrt(y)\n",
    "\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "# fig, ax = plt.subplots(figsize=(7*1.25,5*1.25))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('HOMICIDES')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# --------------- Imputation mit mean ---------------------\n",
    "x = data_all[\"HOMICIDES\"].fillna(data_all[\"HOMICIDES\"].mean())\n",
    "x = x**2\n",
    "# x = np.log(x)\n",
    "y = data_all[\"PISA Math\"].fillna(data_all[\"PISA Math\"].mean())\n",
    "# y = np.log(y)\n",
    "\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "# fig, ax = plt.subplots(figsize=(7,5))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('HOMICIDES')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# --------------- No Imputation ---------------------\n",
    "data = data_all.dropna()\n",
    "x = data[\"HOMICIDES\"]\n",
    "x = x**2\n",
    "# x = np.log(x)\n",
    "y = data[\"PISA Math\"]\n",
    "# y = np.log(y)\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "# fig, ax = plt.subplots(figsize=(7,5))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('HOMICIDES')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log(PCT_EDU_TRY): Evaluation der kNN-Imputation: Vergleich mit mean-Imputation und gar keiner Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- Imputation ----------------------\n",
    "x = data_math[\"log(PCT_EDU_TRY)\"]\n",
    "# x = np.exp(x)\n",
    "# x = np.log(x)\n",
    "# x = np.sqrt(x)\n",
    "y = data_math[\"PISA Math\"]\n",
    "# y = np.log(y)\n",
    "# y = np.sqrt(y)\n",
    "\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "# fig, ax = plt.subplots(figsize=(7, 4))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('log(PCT_EDU_TRY)')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# --------------- Imputation mit mean ---------------------\n",
    "x = data_all[\"log(PCT_EDU_TRY)\"].fillna(data_all[\"log(PCT_EDU_TRY)\"].mean())\n",
    "# x = np.log(x)\n",
    "y = data_all[\"PISA Math\"].fillna(data_all[\"PISA Math\"].mean())\n",
    "# y = np.log(y)\n",
    "\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('log(PCT_EDU_TRY)')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# --------------- No Imputation ---------------------\n",
    "data = data_all.dropna()\n",
    "x = data[\"log(PCT_EDU_TRY)\"]\n",
    "# x = np.log(x)\n",
    "y = data[\"PISA Math\"]\n",
    "# y = np.log(y)\n",
    "#plt.plot(x, y, \"o\", color=\"blue\")\n",
    "r_gini = np.corrcoef(x, y)\n",
    "print(\"r = \" + str(r_gini[0, 1]))\n",
    "\n",
    "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
    "#line\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='x', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('log(PCT_EDU_TRY)')\n",
    "ax.set_ylabel('PISA_MATH')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_all_imputed_exp = data_all_imputed[[\"PISA Math\",\"PISA Read\",\"PISA Science\",\"GINI\",\"log(MIGRANTS)\",\"STR_SRY\",\"log(GDP)\",\"log(EDU_SPENDING_SRY)\",\"CPI\", \"ALC_PC\", \"log(SOCIAL_EXP)\",PATENTS\", \"HOUSING\", \"HDI\"]]\n",
    "# data_all_imputed_exp.to_csv('../data/all_imputed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_math_exp = data_math\n",
    "# data_math_exp.to_csv('../data/math_imputed_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_read_exp = data_read\n",
    "# data_read_exp.to_csv('../data/read_imputed_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_science_exp = data_science\n",
    "# data_science_exp.to_csv('../data/science_imputed_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_all_imputed_exp = data_all_imputed[[\"PISA Math\",\"PISA Read\",\"PISA Science\",\"GINI\",\"log(MIGRANTS)\",\"STR_SRY\",\"log(GDP)\",\"log(EDU_SPENDING_SRY)\",\"CPI\", \"ALC_PC\", \"log(SOCIAL_EXP)\",PATENTS\", \"HOUSING\", \"HDI\"]]\n",
    "# data_all_imputed_exp.to_csv('../data/all_imputed_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
